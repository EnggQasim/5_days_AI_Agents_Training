{
 "cells": [
  {
   "cell_type": "raw",
   "id": "61ec23a2",
   "metadata": {},
   "source": [
    "https://samueldamilare.medium.com/mastering-vector-embeddings-search-text-audio-video-and-images-with-ease-1f1b9f3ec55d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17285300",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq tensorflow_hub  pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a415bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "099a8f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-09 13:41:25.495832: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2024-10-09 13:41:25.495854: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2024-10-09 13:41:25.495860: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2024-10-09 13:41:25.495877: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-10-09 13:41:25.495884: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2024-10-09 13:41:26.761307: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio embedding shape: (34, 1024)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Load the YAMNET model\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "\n",
    "# Load an audio file\n",
    "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audio/h1.wav'))\n",
    "audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "# Generate embeddings\n",
    "scores, embeddings, log_mel_spectrogram = model(audio)\n",
    "\n",
    "print(f\"Audio embedding shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3df3238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio embedding shape: (41, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Load an audio file\n",
    "audio, sample_rate = tf.audio.decode_wav(tf.io.read_file('audio/a2.wav'))\n",
    "audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "scores, embeddings, log_mel_spectrogram = model(audio)\n",
    "\n",
    "print(f\"Audio embedding shape: {embeddings.shape}\")#27,18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0781c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2016, 64), dtype=float32, numpy=\n",
       "array([[-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "        -6.9077554],\n",
       "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "        -6.9077554],\n",
       "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "        -6.9077554],\n",
       "       ...,\n",
       "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "        -6.9077554],\n",
       "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "        -6.9077554],\n",
       "       [-6.9077554, -6.9077554, -6.9077554, ..., -6.9077554, -6.9077554,\n",
       "        -6.9077554]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d4679",
   "metadata": {},
   "source": [
    "#  we found shape dimension error\n",
    "* you can solve with slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5383fe62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio embedding shape: (41, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
      "a2.wav\n",
      "Audio embedding shape: (29, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
      "a1.wav\n",
      "Audio embedding shape: (34, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
      "h1.wav\n",
      "Audio embedding shape: (18, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
      "q2.wav\n",
      "Audio embedding shape: (42, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
      "h2.wav\n",
      "Audio embedding shape: (27, 1024) new shape (5, 1024) type <class 'numpy.ndarray'>\n",
      "q1.wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "voices = []\n",
    "labels = []\n",
    "for i in os.listdir(\"./audio/\"):\n",
    "    if '.wav' in i:\n",
    "        name = i.split(\".\")[0]\n",
    "\n",
    "\n",
    "        audio, sample_rate = tf.audio.decode_wav(tf.io.read_file(f'./audio/{i}'))\n",
    "        audio = tf.squeeze(audio, axis=-1)\n",
    "\n",
    "        scores, embeddings, log_mel_spectrogram = model(audio)\n",
    "\n",
    "        voices.append(np.array(embeddings[:5,:]).ravel())\n",
    "        labels.append(name)\n",
    "\n",
    "        print(f\"Audio embedding shape: {embeddings.shape} new shape {embeddings[:5,:].shape} type {type(np.array(embeddings[:18,:]))}\")#27,18\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da7e4a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.6946361 , 0.36075723, 0.6930015 , ..., 0.9783664 , 0.12747997,\n",
       "        0.        ], dtype=float32),\n",
       " array([0.        , 0.25089428, 0.09453958, ..., 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([2.2192965 , 0.14239739, 0.6774485 , ..., 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([2.103551  , 0.28917295, 0.66041994, ..., 0.        , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " array([1.8627615 , 0.10154425, 0.7127788 , ..., 0.2883861 , 1.3826851 ,\n",
       "        2.7965832 ], dtype=float32),\n",
       " array([2.324272  , 0.17074186, 0.21542566, ..., 0.0181713 , 1.7490327 ,\n",
       "        1.825291  ], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4a47001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports a PyMilvus package:\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema,\n",
    "    CollectionSchema,\n",
    "    DataType,\n",
    "    Collection,\n",
    ")\n",
    "\n",
    "#Connect to the Milvus\n",
    "connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "# Define the collection name\n",
    "collection_name = \"audio\"\n",
    "\n",
    "# Delete old collection if it exists\n",
    "if utility.has_collection(collection_name):\n",
    "    Collection(collection_name).drop()\n",
    "    \n",
    "    \n",
    "#Creates a collection:\n",
    "fields = [\n",
    "    FieldSchema(name=\"pk\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "    FieldSchema(name=\"words\", dtype=DataType.VARCHAR, max_length=50),\n",
    "    FieldSchema(name=\"person_name\", dtype=DataType.VARCHAR, max_length=50),\n",
    "    FieldSchema(name=\"embeddings\", dtype=DataType.FLOAT_VECTOR, dim=5120)\n",
    "]\n",
    "schema = CollectionSchema(fields, \"Simple Demo for audio similar search\")\n",
    "audio = Collection(\"audio\", schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c6ff703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Builds indexes on the entities:\n",
    "\n",
    "index = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 128},\n",
    "}\n",
    "\n",
    "audio.create_index(\"embeddings\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38a067e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a2', 'a1', 'h1', 'q2', 'h2', 'q1']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63acee52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5120,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voices[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "498bb584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert data in collection\n",
    "data = [\n",
    "    [1,2,3,4,5,6],  # field pk\n",
    "    labels,  # field words\n",
    "    [\"Auranzaib\",\"Auranzaib\",\"Hasnant\",\"Qasim\",\"Hasnant\",\"Qasim\"],\n",
    "    voices,  # field embeddings\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f1cecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.insert(data)\n",
    "audio.flush()\n",
    "audio.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "add38b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\"metric_type\": \"L2\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8629381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = audio.search(\n",
    "\tdata=[voices[0]],\n",
    "\tanns_field=\"embeddings\",\n",
    "\tparam=search_params,\n",
    "\tlimit=4,\n",
    "\texpr=None,\n",
    "\t# set the names of the fields you want to retrieve from the search result.\n",
    "\toutput_fields=['words','person_name'],\n",
    "\tconsistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "760df8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auranzaib\n",
      "Auranzaib\n",
      "Qasim\n",
      "Hasnant\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(results[0])):\n",
    "    name = results[0][i].entity.get('words')\n",
    "    pname = results[0][i].entity.get('person_name')\n",
    "    print(pname)\n",
    "#     try:\n",
    "#         display(Image.open('./images/'+name+'.jpg'))\n",
    "#     except:\n",
    "#         display(Image.open('./images/'+name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b1c4b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a2', 'a1', 'h1', 'q2', 'h2', 'q1']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396e25d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
